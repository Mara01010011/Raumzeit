\documentclass[ngerman]{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{color}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=cyan]{hyperref}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{braket}
\newcommand{\erw}[1]{\langle {#1} \rangle}
\newcommand{\Hil}{\mathcal{H}}


\usepackage[backend=bibtex, style=numeric-comp, sorting=nty]{biblatex}
\bibliography{mybib}

%\usepackage{scrpage2}
%\usepackage{booktabs}
%\usepackage{cite}
%\usepackage{makeidx}
%\makeindex
%\pagestyle{scrheadings}
\begin{document}
 
	\begin{titlepage}
		\begin{minipage}[c][\textheight][c]{\textwidth}
			\begin{center}
				{ \Huge \textbf{Thermodynamik schwarzer Löcher} }
				
				\vspace*{1cm}
				{\large eine Seminararbeit von}
				
				\vspace*{0.2cm}
				{\Large Tamara Szecsey}
				
				\vspace*{1cm}
				{\large \today}
				
				\vspace*{4cm}
				\hspace*{1cm} \includegraphics[height=30ex]{LOGO_UR}
			\end{center}
		\end{minipage}
	\end{titlepage}
	
\tableofcontents
\newpage

\section{Informationsentropie allgemein}
Zunächst ein kurzer Einblick, um welche Art von Entropie es sich hier handeln wird. Ludwig Boltzmann hatte festgestellt, dass eine Proportionalität zwischen der Entropie $S$ und $\log W$ herrscht, wobei $W$ die Wahrscheinlichkeit darstellt. Der zugehörige Proportionalitätsfaktor $k$ ist die Boltzmann-Konstante.
	\begin{align}
		S &= k \log W
	\end{align}
Dies ist eine wichtige Verbindung zwischen Statistik und Thermodynamik. 
Die Verallgemeinerte Boltzmannsche Beziehung bring dann die sogenannte Informationsentropie hervor, die in diesen Gestalten geschrieben werden kann:	
	\begin{align} \label{Informationsentropie}
		S &=
		\left\{
		\begin{aligned}
		&- k ~\erw{\,\ln \rho\,} \\
		&-k~ Sp(\rho \ln \rho) \\
		&-k \sum_n \rho_n \ln \rho_n
		\end{aligned}
		\right.
	\end{align}
wobei $\rho$ die Wahrscheinlichkeit ist, die Energie $E_n$ im mikrokanonischen Ensemble anzutreffen. 
(Wir wollen hier nicht weiter auf die thermodynamische Definition der Entropie eingehen, für Fragen zu den Grundlagen siehe \cite{Brenig})

Wie wir jetzt aber zu Information kommen, soll ein Beispiel zeigen. Dabei geht es um eine quantitativen Betrachtung der selben.
Wir betrachten nun eine Reihe von Ereignissen $E_n (n = 1, 2, \ldots, N)$, die mit bestimmten Wahrscheinlichkeiten $\rho_n$ auftreten, wobei
	\begin{align}
		\sum_{n=1}^N \rho_n &= 1
	\end{align}
Nun sehen wir das Eintreten bestimmter die Ereignisse $E_n$, dabei hat jede unserer Feststellungen hat einen Informationswert $I_n$. Nach häufiger Wiederholung kann man einen mittleren Informationsgehalt aufstellen:
	\begin{align}
		I = \sum_{n=1}^N
	\end{align}
Hier legen wir wie in der Informationstheorie fest
	\begin{align} \label{Informationsgehalt}
		I = - \sum \rho_n \mathrm{ld}(\rho_n)
	\end{align}
wobei $\mathrm{ld}(x)$ der dyadische Logarithmus von x ist, also $2^{\mathrm{ld}(x)} = x$. 
Wir haben \eqref{Informationsgehalt} so festgelegt, dass ein Ereignis allein durch eine Ja oder Nein Frage (oder durch 0 und 1) vollständig charakterisierbar ist. 
Dass unserer mittlerer Informationsgehalt unserer Entropie von \eqref{Informationsentropie} ähnlich sieht, ist kein Zufall.

Wir machen nun zwei Zahlenbeispiele zur Veranschaulichung:
	\begin{itemize}
		\item[\textit{1.\,Beispiel:}] Sei $N=2, \rho_1 = \rho_2= \frac{1}{2}$ was sein könnte: Ein Teilchen hält sich mit gleicher Wahrscheinlichkeit in der linken oder rechten Hälfe eines Kastens auf, oder Zahl und Wappen für ein Münzwurf.
		Es benötigt Ja-Nein-Frage, um herauszufingen, wo das Teilchen liegt oder wierum die Münze gefallen ist.
			\begin{align}
				I = \mathrm{ld}(2) = 1 \,\mathrm{bit}
			\end{align}
		Ein bit ist die Einheit für Information.
		\item[\textit{2.\,Beispiel:}]Sei $N=6, \rho_n = \frac{1}{6}$, wobei die Ereignisse $E_n$ die Seiten eines Würfels sein könnten, der Informationsgehalt
			\begin{align}
				I = \mathrm{ld}(6) &= 2,58 \,\mathrm{bit}
			\end{align}
	\end{itemize}
(siehe auch \cite{Brenig})
\section{Verschränkungsentropie / Entanglement Entropy} %S.87
	Von einer Verschränkung spricht man bei Korrelationen zwischen zwei Untersystemen. Wir brauchen sie später für die Informationsentropie.
		
	Es seien zwei Untersysteme $A$ und $B$, das Untersystem $A(B)$ wird beschrieben durch ein komplette Menge an kommutierenden Opservablen $\alpha(\beta)$. Die Zusammensetzung beider Systeme wäre in einem reinen Zustand (falls das unbekannt ist, siehe Anhang \ref{ReinerZustandA}) durch die Wellenfunktion $\Psi(\alpha,\beta)$ beschrieben. Sie sind zunächst separiert voneinander, alle Messungen die an $A(B)$ gemacht werden, können mit Hilfe der Dichtematrix $\rho_A(\rho_B)$ beschrieben werden.
	
	Also für ein $\alpha'$ welches in $\alpha$ übergeht und ein $\beta'$ welches in ein $\beta$ übergeht bedeutet das:
		\begin{align}
			\begin{aligned}
			(\rho_A)_{\alpha \alpha'} &=
			\sum_{\beta} \Psi^*(\alpha, \beta) \Psi(\alpha', \beta) \\
			(\rho_B)_{\beta \beta'} &= 
			\sum_{\alpha} \Psi^* (\alpha, \beta) \Psi (\alpha, \beta')
			\end{aligned}
		\end{align}
	Wir gehen nun von $\rho_A$ aus, um die Eigenschaften der Dichtematrix zu betrachten (wir könnten auch problemlos von $\rho_B$ ausgehen)
	\begin{enumerate}[1)]
		\item Die Dichtematrix ist hermitesch
			\begin{align}
				(\rho_A)_{\alpha \alpha'} &= (\rho_A)^*_{\alpha' \alpha}
			\end{align}
		\item Die Dichtematrix ist positiv semidefinit, also alle ihre Eigenwerte sind 0 oder positiv.
		\item Die Dichtematrix ist auf 1 normalisiert:
			\begin{align}
				Sp \, \rho = 1
			\end{align}
		Das bedeutet nun aber, dass die Eigenwerte nur Zahlen zwischen eins und null annehmen können. Wenn ein Eigenwert von $\rho_A$ gleich 1 ist, dann müssen alle Anderen verschwinden, und in dem Falle wäre dann $A$ in einem reinen Zustand. 
		Dies geschieht nur, wenn die Wellenfunktion sich wie folgt faktorisieren lässt:
			\begin{align}
				\Psi (\alpha, \beta) &= \psi_A(\alpha) \psi_B (\beta)
			\end{align} 
		(hier wäre auch $B$ in einem reinen Zustand)
		\item 
	\end{enumerate}
	
\section{Evaporation}
	Stephen Hawking hat in seinem Paper \cite{ParticleCreation} gezeigt, dass ein großes schwarzes Loch für einen Beobachter in großer Ferne eine Temperatur besitzt:
		\begin{align}
			T = \frac{1}{8 \pi MG}
		\end{align}

\section{Die Bekenstein-Hawking Entropie}
Zunächst betrachten wir Gründe, warum ein schwarzes Loch Entropie besitzen muss. 
	\begin{itemize}
		\item Zum einen Form es sich normalerweise durch kollabierende Materie, die eine 	bestimmte Masse haben oder Strahlung abgeben. Beide enthalten 		Entropie. Wir können nach der Entstehung des schwarzen Lochs nicht mehr über den Horizont hinweg sehen, also können wir keine thermodynamische Aussage auf Grundlage der zuvor kollabierten Materie machen, weil sie unbeobachtbar ist. Aber mit einer dem schwarzen Loch zugeordeten Entropie ist das möglich.
		
		\item Ein schwarzes Loch kann mich ein paar wenigen Parametern beschrieben werden, nämlich Masse, elektrische Ladung und Drehmoment. Da für eine beliebige Wahl dieser Zahlen eine Menge Möglichkeiten bestehen, wie das Schwarze Loch entstanden sein könnte, stimmen viele inneren Zustände mit ihm überein. Das passt auch zur Thermodynamik, in der viele Mikrozustände einen Makrozustand bilden können. Genau diesen weiß die Entropie zu beschreiben, deshalb muss ein schwarzes Loch diese haben. 
		
		\item Das Schwarze Loch blockt alle Signale und verhindert somit, dass keine Information über es an die Außenwelt gelangen kann. So gesehen kann man sagen, dass es Information versteckt, die aber durch die Entropie gemessen werden kann. Deshalb macht es Sinn dem schwarzen Loch eine Entropie zuzuschreiben. 
	\end{itemize}

\section{Das holographische Prinzip}

\section{Wirkungsintegrale}

\section{Loop Quantum Gravity (LQG)}	

\appendix
\section{Reiner Zustand} \label{ReinerZustandA}
Sei $\rho$ die \textit{Dichtematrix} welche ein Quantenzustand im Hilbertraum ist $\Hil$. Quantenzustände werden allgemein mit Operatoren dargestellt, hier: $\rho$ ist ein nicht negativer, hermitescher Operator mit Spur 1. Wenn es in der Form
\begin{equation}
\rho=\ket{\psi} \bra{\psi},
\end{equation}
geschrieben werden kann, dann heißt der \textit{rein}. Wenn ein Zustand nicht rein ist, dann ist er \textit{gemischt}.

\section{Zustände in der Thermodynamik}

\subsection*{Mikrozustand}
Ein Mikrozustand ist im klassischen Fall ein Punkt im Phasenraum. Damit ist Ort und Impuls für jedes Teilchen gegeben.

\subsection*{Makrozustand}
Viele Mikrozustände bilden einen Makrozustand, der durch Parameter dargestellt ist, die nicht mehr direkt mit Ort oder Impuls einzelner Teilchen zu tun hat.

\newpage
\printbibliography
%\printindex
\end{document}